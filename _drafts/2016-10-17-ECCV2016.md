---
title: "ECCV 2016"
excerpt: "Where to deep learning?"
comments: true
share: true
header:
  teaser: 3Dreconstruction.jpg
---

I recently had the opportunity to attend [ECCV 2016](http://eccv2016.com) to present our [SPICE](/spice/) metric for image captioning. It was a great conference, with a really friendly atmosphere and plenty of exciting ideas. ANU and the [ACRV](http://roboticvision.org) were well represented so congrats to all authors and prizewinners. 

## What's missing from deep learning?

Okay, let's start with deep learning which according to the organizers was the single largest subject area for both submitted and accepted papers. At high level, a lot of papers are presenting new or modified deep learning architectures demonstrating improved performance for particular tasks. For example, [this paper used iterative refinement in a net for pose tracking and it worked really well](link). In no way do I intend to minimise these contributions, which require substantial insight and a lot of hard work. However, it seems to me that there are two things missing in the deep learning community.

Outside of the paper presentations, I saw two very interesting presentations from Max Welling and Bengio, both of which touched on 'what's missing' from deep learning at the moment. 

In the spirit of these talks I will offer my own very pragmatic view of what's missing from deep learning, based on what I saw at the conference. The first missing piece is a genuine understanding of *deep learning design patterns*. At lot of current work is focused on developing new or modified deep learning architectures demonstrating improved performance for particular tasks. For example, [this paper used iterative refinement in a net for pose tracking and it worked really well](link). Perhaps in a few years from now, I would love to see all this accumulated experience and wisdom captured in a compendium of deep learning desing patterns, illustrating what works well in certain situations, much like the original (link). For example, attention pattern - useful when . Alternative - neural memory units. 

The second missing piece, for want of a better term, I will call a Network Description Language (NDL). What I'm talking about is a standard language to describe the structure and behaviour of neural network architectures. Having listened to the ECCV presentations and started reading the papers, I can't help but feel we have moved way beyond the capacity of current formats -- block diagrams, supported by equations and text -- to accurately convey this information. While code is the ultimate documentation, code releases are complicated due to the number of different deep learning frameworks in use (including proprietary ones). A Network Description Language would be platform-independent, allowing networks to be accurately described, and ultimately, designed, without being tied to a particular software framework. I'm sure it's no accident that the digital circuit design ecosystem revolves around two standard Hardware Description Languages. I bet we could borrow a lot of good ideas from existing data-flow languages such as VHDL and Verilog.

Edit: I hear you saying, isn't Caffe's protobuf similar to a Network Description Language? The answer is, not really. Caffe's protobuf's make reference to Caffe layers, so they are tied to the Caffe implementation. If I change the 'Convolution' layer in the Caffe source, the protobuf now means something different. Secondly, if you've ever used a python script to lay out a large recurrent network in protobuf, you would agree that it is very verbose. A good Network Description Language needs loops and variables to specify repeated structure. Thirdly, Caffe protobuf is limited to predefined Caffe models - it can't be used to specify new components.  





